{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('azdiabetes.csv')\n",
    "# Exclude the 'diabetes' variable\n",
    "X = df.drop(columns=['diabetes', 'glu'])\n",
    "X['intercept'] = 1\n",
    "X = X[['intercept', 'npreg', 'bp', 'bmi', 'ped', 'age']].values\n",
    "\n",
    "y = df['glu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prior parameters\n",
    "n = 532\n",
    "g = n\n",
    "nu0 = 2\n",
    "sigma02 = 1\n",
    "\n",
    "# number of independent samples\n",
    "s = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#sample from the distributions\n",
    "factor = X @ np.linalg.inv(X.T @ X) @ X.T\n",
    "SSRg = (y.T) @ (np.identity(n) - (g/(g+1)) * factor) @ y\n",
    "shape = (nu0 + n) / 2\n",
    "scale = (nu0 * sigma02 + SSRg) / 2\n",
    "gamma_samples = stats.gamma.rvs(a=shape, scale=scale, size=s)\n",
    "\n",
    "# Sample variance\n",
    "sigma = 1 / math.sqrt(sum(gamma_samples)/s)\n",
    "\n",
    "# Generate independent Monte Carlo samples\n",
    "mean = (g/(g+1)) * (np.linalg.inv(X.T @ X) @ np.array(X.T) @ y)\n",
    "cov = (g/(g+1)) * (sum(gamma_samples)/s) * np.linalg.inv(X.T @ X)\n",
    "\n",
    "mvnormal_samples = np.random.multivariate_normal(mean, cov, s)\n",
    "\n",
    "beta = sum(mvnormal_samples) / s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection by Gibbs sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import gammaln\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# log probability\n",
    "def lp_y_X(y, X):\n",
    "    \n",
    "    n, p = X.shape\n",
    "    \n",
    "    if p == 0:\n",
    "        Hg = 0\n",
    "        sigma02 = np.mean(y**2)\n",
    "    else:\n",
    "        Hg = (g/(g+1)) * factor\n",
    "        sigma02 = sm.OLS(y, X).fit().mse_resid\n",
    "    \n",
    "    SSRg = y.T @ (np.identity(n) - Hg) @ y \n",
    "    log_prob = -0.5 * (n * np.log(np.pi) + p * np.log(1 + g) \n",
    "                       + (nu0 + n) * np.log(nu0 * sigma02 + SSRg) \n",
    "                       - nu0 * np.log(nu0 * sigma02)) + gammaln((nu0 + n) / 2) - gammaln(nu0 / 2)\n",
    "    return log_prob\n",
    "\n",
    "# Starting values and MCMC setup\n",
    "S = 10000\n",
    "Z = np.zeros((S, 6))\n",
    "z = np.zeros(X.shape[1])\n",
    "\n",
    "# Initial log probability\n",
    "lp_y_c = lp_y_X(y, X[:, z == 1])\n",
    "\n",
    "# Gibbs sampler\n",
    "for s in range(S):\n",
    "    for j in np.random.permutation(X.shape[1]):\n",
    "        zp = z.copy()\n",
    "        zp[j] = 1 - zp[j]\n",
    "        lp_y_p = lp_y_X(y, X[:, zp == 1])\n",
    "        r = (lp_y_p - lp_y_c) * (-1) ** (zp[j] == 0)\n",
    "        z[j] = np.random.binomial(1, 1 / (1 + np.exp(-r))) # whether to accept\n",
    "        if z[j] == zp[j]:\n",
    "            lp_y_c = lp_y_p\n",
    "    Z[s, :] = z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/lgsl3l_d7fv4z40yrx07rfz80000gn/T/ipykernel_97148/3048451862.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y1 = df['diabetes'].replace({'Yes': 1, 'No': 0})\n"
     ]
    }
   ],
   "source": [
    "X1 = df[['npreg', 'bp', 'bmi', 'ped', 'age']]\n",
    "\n",
    "# centering and scaling\n",
    "means = X1.mean()\n",
    "stds = X1.std()\n",
    "X_scaled = (X1 - means) / stds\n",
    "X_scaled['intercept'] = 1\n",
    "X_scaled = X_scaled[['intercept', 'npreg', 'bp', 'bmi', 'ped', 'age']].values\n",
    "\n",
    "\n",
    "y1 = df['diabetes'].replace({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from numpy.random import uniform\n",
    "\n",
    "# Likelihood function\n",
    "def likelihood(x):\n",
    "    return np.exp(x) / (1 + np.exp(x))\n",
    "\n",
    "# Initial values\n",
    "n_iter = 10000\n",
    "beta = np.ones(6)\n",
    "gamma = np.zeros(6)\n",
    "standard = np.ones(len(y1))\n",
    "p_beta = multivariate_normal.pdf(beta, np.zeros(6),\n",
    "                                 np.diag([16, 4, 4, 4, 4, 4]))\n",
    "\n",
    "# Store samples\n",
    "beta_samples = np.zeros((n_iter, 6))\n",
    "gamma_samples = np.zeros((n_iter, 6))\n",
    "\n",
    "# proporsal variance can be approximated by \\sigma^2(X^{T} X)^{-1}, which is close to the posterior variance of \\beta\n",
    "var_prop = np.var(np.log(y1+1/2)) * np.linalg.inv(X_scaled.T @ X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metropolis-Hastings sampling\n",
    "for i in range(n_iter):\n",
    "    # Sample beta\n",
    "    beta_prop = np.random.multivariate_normal(beta, var_prop)\n",
    "    J_prop_beta = multivariate_normal.pdf(beta_prop, beta, var_prop)\n",
    "    p_prop_beta = multivariate_normal.pdf(beta_prop, np.zeros(6),\n",
    "                                          np.diag([16, 4, 4, 4, 4, 4]))\n",
    "    J_beta = multivariate_normal.pdf(beta, beta_prop, var_prop)\n",
    "\n",
    "    L_prop_beta = sum(np.log(likelihood(np.sum(beta_prop * gamma * X_scaled, axis=1))**y1\n",
    "                             * (standard - likelihood(np.sum(beta_prop * gamma * X_scaled, axis=1)))**(1-y1)))\n",
    "    \n",
    "    L_beta = sum(np.log(likelihood(np.sum(beta * gamma * X_scaled, axis=1))**y1\n",
    "                        * (standard - likelihood(np.sum(beta * gamma * X_scaled, axis=1)))**(1-y1)))\n",
    "\n",
    "    r_log_beta = L_prop_beta + np.log(p_prop_beta) - L_beta - np.log(p_beta) + np.log(J_beta) - np.log(J_prop_beta)\n",
    "\n",
    "    if np.log(uniform()) < min(0, r_log_beta):\n",
    "        beta = beta_prop\n",
    "        p_beta = p_prop_beta\n",
    "\n",
    "    beta_samples[i] = beta\n",
    "\n",
    "    # Sample gamma\n",
    "    for r in np.random.permutation(range(1,6)):\n",
    "        gamma_prop = gamma.copy()\n",
    "        gamma_prop[r] = 1 - gamma_prop[r]\n",
    "\n",
    "        L_prop_gamma = sum(np.log(likelihood(np.sum(beta * gamma_prop * X_scaled, axis=1))**y1\n",
    "                                  * (standard - likelihood(np.sum(beta * gamma_prop * X_scaled, axis=1)))**(1-y1)))\n",
    "        \n",
    "        L_gamma = sum(np.log(likelihood(np.sum(beta * gamma * X_scaled, axis=1))**y1\n",
    "                        * (standard - likelihood(np.sum(beta * gamma * X_scaled, axis=1)))**(1-y1)))\n",
    "\n",
    "        r_log_gamma = L_prop_gamma - L_gamma\n",
    "\n",
    "        if np.log(uniform()) < min(0, r_log_gamma):\n",
    "            gamma = gamma_prop\n",
    "    \n",
    "    gamma_samples[i] = gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs Sampling by Pólya-Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from polyagamma import random_polyagamma\n",
    "\n",
    "# Initial values\n",
    "n_iter = 10000\n",
    "beta = np.ones(6)\n",
    "gamma = np.zeros(6)\n",
    "\n",
    "# Store samples\n",
    "beta_samples = np.zeros((n_iter, 6))\n",
    "omega_samples = np.zeros((n_iter, len(y1)))\n",
    "pz_samples = np.zeros((n_iter, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gibbs sampling by Pólya-Gamma\n",
    "for i in range(n_iter):\n",
    "    # Sample omega\n",
    "    omega = np.zeros(len(y1))\n",
    "    for r in range(len(y1)):\n",
    "        x = X_scaled[r]\n",
    "        omega[r] = random_polyagamma(1, np.dot(x, beta), size=1)[0]\n",
    "        \n",
    "    omega_samples[i] = omega\n",
    "\n",
    "    # Sample beta\n",
    "    B = np.diag([16, 4, 4, 4, 4, 4])\n",
    "    b = np.zeros(6)\n",
    "    V_omega = np.linalg.inv(X_scaled.T @ np.diag(omega) @ X_scaled + np.linalg.inv(B)) # use of X_scaled\n",
    "    k = y1 - np.ones(len(y1))/2\n",
    "    m_omega = V_omega @ (X_scaled.T @ k + np.linalg.inv(B) @ b)\n",
    "    beta = np.random.multivariate_normal(m_omega, V_omega)\n",
    "    beta_samples[i] = beta\n",
    "\n",
    "\n",
    "    # Sample gamma\n",
    "    for r in np.random.permutation(range(1,6)):\n",
    "        gamma_prop = gamma.copy()\n",
    "        gamma_prop[r] = 1 - gamma_prop[r]\n",
    "\n",
    "        L_prop_gamma = sum(np.log(likelihood(np.sum(beta * gamma_prop * X_scaled, axis=1))**y1\n",
    "                                  * (standard - likelihood(np.sum(beta * gamma_prop * X_scaled, axis=1)))**(1-y1)))\n",
    "        \n",
    "        L_gamma = sum(np.log(likelihood(np.sum(beta * gamma * X_scaled, axis=1))**y1\n",
    "                        * (standard - likelihood(np.sum(beta * gamma * X_scaled, axis=1)))**(1-y1)))\n",
    "\n",
    "        r_log_gamma = L_prop_gamma - L_gamma\n",
    "\n",
    "        if np.log(uniform()) < min(0, r_log_gamma):\n",
    "            gamma = gamma_prop\n",
    "    \n",
    "    pz_samples[i] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 1., 1., 0.],\n",
       "       [0., 1., 0., 1., 1., 0.],\n",
       "       [0., 1., 0., 1., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1.],\n",
       "       [0., 0., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0., 1., 1., 1.],\n",
       "       [0., 1., 0., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pz_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([1,0,1,1,0])\n",
    "\n",
    "x = 5*np.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[z==1] = np.array(range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 5., 1., 2., 5.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True, False])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
